# -*- coding: utf-8 -*-
import os, ctypes, time, tempfile
import numpy as np
import sounddevice as sd, soundfile as sf
from faster_whisper import WhisperModel
from ollama import Client
import pyttsx3

# ---------- Mossy FO4 Modding Personality ----------
MOD_SYSTEM_PROMPT = """You are Mossy, a hands-on Fallout 4 modding assistant.
Context:
- User mods Fallout 4 with Mod Organizer 2 (MO2).
- Primary tools: FO4Edit (xEdit), Creation Kit, Blender 4.5, NifSkope, GIMP 3.0.4, Upscayl, NVIDIA Texture Tools Exporter 2024.1.1, Materializer, ShaderMap 4, Photopea, KREA.
- File formats: NIF, DDS, BA2, BGSM/BGEM, ESP/ESM/ESL, INI/JSON configs.
- Common tasks: creating textures (BC1/BC7, glow maps, parallax), mesh edits (collision, vertex colors, decimation), conflict resolution in FO4Edit, quest/dialogue setup in CK, packaging mods for Nexus.

Behavior:
- Always give step-by-step, Fallout 4–specific instructions.
- Use exact menu paths, settings, or checkbox names from these tools when possible.
- If the user hits an error, explain likely causes and fixes in plain terms.
- Keep answers pragmatic and modder-focused, not generic.
- When tools overlap, recommend the one most stable for FO4 workflows.
- Assume the user learns best by seeing and doing; be detailed but not fluffy.
"""

# ---------- Local project / skills ----------
PROJECT_ROOT = r"C:\Mods\MyProject"      # <--- set to your workspace
TODO_PATH    = os.path.join(PROJECT_ROOT, "MOSSY_TODO.md")

def skill_search(term, exts=(".psc",".pex",".ini",".toml",".json",".txt",".log",".xml",
                             ".yaml",".cfg",".bat",".py",".cs",".cpp",".h",".dds",".nif",".bgsm",".bgem",".esp",".esm",".esl")):
    term_l = term.lower().strip()
    if not term_l:
        return "Give me a search term, e.g., 'mossy search papyrus'."
    hits = []
    for root, _, files in os.walk(PROJECT_ROOT):
        for f in files:
            if f.lower().endswith(exts):
                p = os.path.join(root, f)
                try:
                    with open(p, "r", encoding="utf-8", errors="ignore") as fh:
                        if term_l in fh.read().lower():
                            hits.append(p)
                except Exception:
                    pass
                if len(hits) >= 50:
                    return f"Found {len(hits)} matches (showing first 50):\n" + "\n".join(hits[:50])
    return "No matches found." if not hits else "\n".join(hits[:50])

def skill_explain_file(path):
    path = path.strip().strip('"')
    if not path or not os.path.exists(path):
        return f"File not found: {path}"
    try:
        with open(path, "r", encoding="utf-8", errors="ignore") as fh:
            content = fh.read()
    except Exception as e:
        return f"Couldn't read file: {e}"
    prompt = (
        "Explain this file to a Fallout 4 modder: what it does, important parts, and how to safely modify it. "
        "If it's config, note key options; if it's script, outline logic.\n\n---\n" + content[:12000]
    )
    return ask_ollama(prompt)

def skill_grep_logs(pattern, log_dir=r"C:\Mods\Logs"):
    patt = (pattern or "").strip()
    if not patt:
        return "Give me a pattern, e.g., 'mossy grep missing master'."
    out = []
    for root, _, files in os.walk(log_dir):
        for f in files:
            if f.lower().endswith((".log",".txt")):
                p = os.path.join(root, f)
                try:
                    with open(p, "r", encoding="utf-8", errors="ignore") as fh:
                        lines = fh.readlines()
                    for i, line in enumerate(lines):
                        if patt.lower() in line.lower():
                            snippet = "".join(lines[max(0,i-2):i+3])
                            out.append((p, i+1, snippet))
                except Exception:
                    pass
                if len(out) >= 20:
                    break
    if not out:
        return f"No log lines matching '{patt}'."
    show = []
    for p, lineno, snippet in out[:5]:
        show.append(f"{p}:{lineno}\n{snippet}\n---")
    return "\n".join(show)

def skill_add_todo(text):
    item = (text or "").strip()
    if not item:
        return "Give me a todo item, e.g., 'mossy todo convert textures to BC7'."
    os.makedirs(PROJECT_ROOT, exist_ok=True)
    with open(TODO_PATH, "a", encoding="utf-8") as fh:
        fh.write(f"- [ ] {item}\n")
    return f"Added to TODO: {item}"

def handle_skill(text: str):
    """Return string if a skill handled the text; otherwise None."""
    t = (text or "").strip()
    tl = t.lower()
    # quick FO4-specific helpers
    if tl.startswith(("mossy bgsm ", "bgsm ")):
        path = t.split(" ", 1)[1] if " " in t else ""
        return (f"Open {path} in Material Editor/BGSM tool. Verify texture paths, set Alpha/Glow flags as needed, "
                f"and use BC7 compression for the linked DDS where appropriate.")
    if " prp" in tl or tl.startswith("prp "):
        return ("PRP (Previsibines Repair Pack): keep your edits ESL-flagged where possible; avoid breaking previs/occlusion. "
                "In FO4Edit, forward necessary records; if you modify cells, regenerate LOD/previs as needed.")

    # generic skills
    if tl.startswith(("mossy search ", "search ")):
        term = t.split(" ", 1)[1] if " " in t else ""
        return skill_search(term)
    if tl.startswith(("mossy explain ", "explain ")):
        path = t.split(" ", 1)[1] if " " in t else ""
        return skill_explain_file(path)
    if tl.startswith(("mossy grep ", "grep ")):
        pattern = t.split(" ", 1)[1] if " " in t else ""
        return skill_grep_logs(pattern)
    if tl.startswith(("mossy todo ", "todo ")):
        item = t.split(" ", 1)[1] if " " in t else ""
        return skill_add_todo(item)
    return None

# ---------- DLL search paths (your working ones) ----------
for p in (
    r"C:\Users\billy\.ai-navigator\conda\envs\navigator\Library\bin",
    r"C:\Program Files\NVIDIA\CUDNN\v9.13\bin\12.9",
    r"C:\Program Files\NVIDIA\CUDNN\v9.13\bin\13.0",
):
    try:
        os.add_dll_directory(p)
    except Exception:
        pass

def _try(path):
    if os.path.exists(path):
        try:
            ctypes.WinDLL(path)
            print("Loaded:", path)
        except Exception as e:
            print("Failed:", path, "->", e)

# CUDA runtime + JIT bits (load what exists on your system)
for name in ["cudart64_12.dll","cublasLt64_12.dll","cublas64_12.dll","nvrtc64_120_0.dll","nvJitLink64_12.dll"]:
    _try(os.path.join(r"C:\Users\billy\.ai-navigator\conda\envs\navigator\Library\bin", name))

# cuDNN v9 libs including engines
for name in [
    "cudnn64_9.dll","cudnn_ops64_9.dll","cudnn_cnn64_9.dll","cudnn_adv64_9.dll",
    "cudnn_graph64_9.dll","cudnn_heuristic64_9.dll",
    "cudnn_engines_precompiled64_9.dll","cudnn_engines_runtime_compiled64_9.dll",
]:
    _try(os.path.join(r"C:\Program Files\NVIDIA\CUDNN\v9.13\bin\12.9", name))

# ---------- Whisper (CUDA -> CPU fallback) ----------
try:
    whisper_model = WhisperModel("small", device="cuda", compute_type="float16")
    print("Whisper loaded on CUDA")
except Exception as e:
    print("Falling back to CPU:", e)
    whisper_model = WhisperModel("small", device="cpu", compute_type="int8")

# ---------- Ollama + TTS ----------
ollama = Client(host="http://localhost:11434")
tts = pyttsx3.init(); tts.setProperty("rate", 170)

# ---------- Audio input selection ----------
DEFAULT_SECONDS = 12     # longer window = fewer cutoffs
FORCE_SAMPLE_RATE = 16000  # accuracy: capture at 16k

def list_input_devices():
    devs = sd.query_devices(); apis = sd.query_hostapis(); out=[]
    for i,d in enumerate(devs):
        if d["max_input_channels"]>0: out.append((i,d["name"],apis[d["hostapi"]]["name"]))
    return out

def try_open(device, rate):
    try:
        sd.check_input_settings(device=device, samplerate=rate, channels=1)
        with sd.InputStream(device=device, samplerate=rate, channels=1, dtype="float32"): pass
        return True
    except Exception:
        return False

def pick_working_input():
    devices = list_input_devices()
    def score(e):
        idx,name,host=e; n=name.lower(); h=host.lower(); s=0
        if "jounivo" in n: s+=5
        if "mic" in n or "microphone" in n: s+=3
        if "wasapi" in h: s+=3
        elif "directsound" in h: s+=2
        elif "mme" in h: s+=1
        return (s,-idx)
    devices.sort(key=score, reverse=True)
    # Try 16k first (best for Whisper), then 44.1k/48k as fallback
    for r in (16000, 44100, 48000):
        for idx,name,host in devices:
            if try_open(idx,r):
                print(f"Selected input device {idx} ({name} via {host}) @ {r} Hz")
                return idx,r
    print("No preferred device opened; default @ 16000 Hz")
    return None, 16000

INPUT_DEVICE, PICKED_RATE = pick_working_input()

def record_wav(duration=DEFAULT_SECONDS, rate=None, device_index=None):
    # Always record at 16k for Whisper accuracy; if device can't, fall back to picked rate.
    rate = FORCE_SAMPLE_RATE if try_open(INPUT_DEVICE, FORCE_SAMPLE_RATE) else PICKED_RATE
    if device_index is None: device_index = INPUT_DEVICE
    if device_index is not None: sd.default.device = (device_index, None)
    print(f"Recording {duration}s @ {rate}Hz; device={sd.default.device}")
    audio = sd.rec(int(duration*rate), samplerate=rate, channels=1, dtype="float32")
    sd.wait()
    peak = float(np.max(np.abs(audio))) if audio.size else 0.0
    rms  = float(np.sqrt(np.mean(audio**2))) if audio.size else 0.0
    print(f"Audio level — peak={peak:.4f}, rms={rms:.4f}")
    tmp = tempfile.NamedTemporaryFile(suffix=".wav", delete=False).name
    sf.write(tmp, audio, rate)
    return tmp, peak, rms

# ---------- Accurate transcription (beam + VAD) ----------
def transcribe(path):
    segments, info = whisper_model.transcribe(
        path,
        task="transcribe",
        language=None,                 # auto-detect (set "en" to force)
        vad_filter=True,               # voice activity detection ON
        vad_parameters=dict(
            min_silence_duration_ms=300,   # keep short pauses
        ),
        beam_size=5, best_of=5,
        patience=1.0, length_penalty=1.0,
        no_speech_threshold=0.5,
        log_prob_threshold=-1.0,
        compression_ratio_threshold=2.4,
        condition_on_previous_text=True,
        without_timestamps=True,
    )
    parts = [getattr(s, "text", "").strip() for s in segments if getattr(s, "text", "").strip()]
    text = " ".join(parts).strip()
    print(f"DEBUG: segments={len(parts)}")
    return text, getattr(info, "language", "en")

# ---------- Robust Ollama response extraction ----------
def ask_ollama(prompt, model="llama3"):
    messages = [
        {"role": "system", "content": MOD_SYSTEM_PROMPT},
        {"role": "user",   "content": prompt},
    ]
    resp = ollama.chat(model=model, messages=messages)

    if isinstance(resp, dict):
        msg = resp.get("message") or {}
        if isinstance(msg, dict) and "content" in msg:
            return msg["content"]
        for k in ("output","response","text","content"):
            if k in resp: return resp[k]
        if "messages" in resp and resp["messages"]:
            maybe = resp["messages"][-1]
            if isinstance(maybe, dict) and "content" in maybe:
                return maybe["content"]
        return str(resp)

    try:
        msg = getattr(resp, "message", None)
        if msg is not None:
            content = getattr(msg, "content", None)
            if isinstance(content, str):
                return content
    except Exception:
        pass

    if isinstance(resp, str): return resp
    return str(resp)

def speak(text):
    print("Mossy:", text)
    tts.say(text); tts.runAndWait()

def main():
    print("Press Enter to talk (12s), or type 'q' to quit.")
    while True:
        cmd = input("> ").strip().lower()
        if cmd == "q": break
        wav, peak, rms = record_wav()
        if peak < 0.01 and rms < 0.002:
            print("I heard almost nothing — check mic or speak closer/louder.")
        text, lang = transcribe(wav)
        print("You said:", text)

        # Run skills first (search/explain/grep/todo)
        skill_reply = handle_skill(text)
        if skill_reply:
            speak(skill_reply)
            continue

        if not text:
            speak("I didn't catch that. Try again."); continue

        reply = ask_ollama(text, model="llama3")  # change model if you like
        speak(reply)

if __name__ == "__main__":
    main()

